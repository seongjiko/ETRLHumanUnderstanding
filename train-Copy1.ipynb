{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision.transforms as v2\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.cli import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)  # Python 내장 random 모듈\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # 환경변수 설정\n",
    "    np.random.seed(seed)  # NumPy\n",
    "    torch.manual_seed(seed)  # PyTorch CPU 시드 고정\n",
    "    torch.cuda.manual_seed(seed)  # PyTorch GPU 시드 고정\n",
    "    torch.cuda.manual_seed_all(seed)  # 멀티 GPU 환경에서도 시드 고정\n",
    "    torch.backends.cudnn.deterministic = True  # CuDNN 관련 설정\n",
    "    torch.backends.cudnn.benchmark = False  # 동일한 입력 크기의 데이터가 반복될 경우 속도 향상을 위한 벤치마크 모드 비활성화\n",
    "\n",
    "# 사용 예시\n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 경로 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train_df = pd.read_csv('../../../origin_datasets/train_label.csv')\n",
    "# # train_df['data_path'] = train_df.apply(lambda row: f\"../new_image_dataset/{row['subject_id']}_{row['date']}_train.png\", axis=1)\n",
    "\n",
    "# valid_df = pd.read_csv('../../../origin_datasets/val_label.csv')\n",
    "# valid_df['data_path'] = valid_df.apply(lambda row: f\"../new_image_dataset/user{row['subject_id']}_{row['date']}_valid.png\", axis=1)\n",
    "\n",
    "# # test_df = pd.read_csv('../../../origin_datasets/answer_sample.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/hdd1/ICTC2024/huni_code/val_label.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# valid_df = pd.read_csv('../../../origin_datasets/val_label.csv')\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m valid_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/hdd1/ICTC2024/huni_code/val_label.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# valid_df['data_path'] = valid_df.apply(lambda row: f\"../new_image_dataset/user{row['subject_id']}_{row['date']}_valid.png\", axis=1)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m valid_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_path\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m valid_df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/hdd1/ICTC2024/huni_code/code/image_si/new_image_dataset/user\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubject_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_valid.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/hdd1/ICTC2024/huni_code/val_label.csv'"
     ]
    }
   ],
   "source": [
    "# valid_df = pd.read_csv('../../../origin_datasets/val_label.csv')\n",
    "valid_df = pd.read_csv('/home/hdd1/ICTC2024/huni_code/val_label.csv')\n",
    "# valid_df['data_path'] = valid_df.apply(lambda row: f\"../new_image_dataset/user{row['subject_id']}_{row['date']}_valid.png\", axis=1)\n",
    "valid_df['data_path'] = valid_df.apply(lambda row: f\"/home/hdd1/ICTC2024/huni_code/code/image_si/new_image_dataset/user{row['subject_id']}_{row['date']}_valid.png\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['subject_id'] = train_df['subject_id'].apply(lambda x: f'{x}_train')\n",
    "valid_df['subject_id'] = valid_df['subject_id'].apply(lambda x: f'user{str(x).zfill(2)}_valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>date</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>data_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user01_valid</td>\n",
       "      <td>2023-08-20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/hdd1/ICTC2024/huni_code/code/image_si/ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user01_valid</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/hdd1/ICTC2024/huni_code/code/image_si/ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user01_valid</td>\n",
       "      <td>2023-08-22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/hdd1/ICTC2024/huni_code/code/image_si/ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user01_valid</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/hdd1/ICTC2024/huni_code/code/image_si/ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user01_valid</td>\n",
       "      <td>2023-08-24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/hdd1/ICTC2024/huni_code/code/image_si/ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject_id        date  Q1  Q2  Q3  S1  S2  S3  S4  \\\n",
       "0  user01_valid  2023-08-20   1   1   1   0   0   0   0   \n",
       "1  user01_valid  2023-08-21   1   1   1   0   0   1   0   \n",
       "2  user01_valid  2023-08-22   0   1   1   0   1   1   0   \n",
       "3  user01_valid  2023-08-23   0   1   1   0   0   1   0   \n",
       "4  user01_valid  2023-08-24   1   1   1   0   0   1   0   \n",
       "\n",
       "                                           data_path  \n",
       "0  /home/hdd1/ICTC2024/huni_code/code/image_si/ne...  \n",
       "1  /home/hdd1/ICTC2024/huni_code/code/image_si/ne...  \n",
       "2  /home/hdd1/ICTC2024/huni_code/code/image_si/ne...  \n",
       "3  /home/hdd1/ICTC2024/huni_code/code/image_si/ne...  \n",
       "4  /home/hdd1/ICTC2024/huni_code/code/image_si/ne...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, valid_df = train_test_split(valid_df, test_size = 0.2, random_state=1020)\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "# final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count >>> train_set: 84, valid_set: 21\n"
     ]
    }
   ],
   "source": [
    "print(f\"count >>> train_set: {len(train_df)}, valid_set: {len(valid_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(self, df, transforms):\n",
    "#         self.path = df['data_path'].values\n",
    "#         self.class_ = df[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3', 'S4']].values\n",
    "#         self.transform = transforms\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         try:\n",
    "#             img = np.array(Image.open(self.path[idx]).convert('RGB'))\n",
    "#         except FileNotFoundError:\n",
    "#             # If file not found, skip to the next item\n",
    "#             return self.__getitem__((idx + 1) % len(self))\n",
    "        \n",
    "#         img = self.transform(image=img)\n",
    "#         img = img[\"image\"]\n",
    "        \n",
    "#         y = self.class_[idx]\n",
    "        \n",
    "#         return img, y\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.path)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transforms):\n",
    "        self.path = df['data_path'].values\n",
    "        self.class_ = df[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3', 'S4']].values\n",
    "        self.transform = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img = np.array(Image.open(self.path[idx]).convert('RGB'))\n",
    "        except FileNotFoundError:\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "        \n",
    "        img = self.transform(image=img)['image']\n",
    "        img = torch.tensor(img, dtype=torch.float)  # Explicitly specify the type as float\n",
    "        y = self.class_[idx]\n",
    "        \n",
    "        return img, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 mean, std 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# import albumentations as A\n",
    "\n",
    "# # 이미지가 저장된 폴더 경로\n",
    "# folder_path = '../new_image_dataset'\n",
    "\n",
    "# # 이미지 파일 목록 가져오기\n",
    "# image_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "# # 모든 이미지를 읽어 numpy 배열에 저장\n",
    "# images = []\n",
    "# for file in image_files:\n",
    "#     image_path = os.path.join(folder_path, file)\n",
    "#     image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # 흑백 이미지로 읽기\n",
    "#     if image is not None:\n",
    "#         images.append(image)\n",
    "\n",
    "# # 이미지 배열을 numpy 배열로 변환\n",
    "# images_array = np.array(images)\n",
    "\n",
    "# # 각 픽셀의 평균과 표준편차 계산\n",
    "# mean = np.mean(images_array)\n",
    "# std = np.std(images_array)\n",
    "\n",
    "# # 결과 출력\n",
    "# print(f\"Mean: {mean}, Std: {std}\")\n",
    "\n",
    "mean = 15.359733188267395\n",
    "std = 58.28444875927197\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "class RandomHorizontalStrips(ImageOnlyTransform):\n",
    "    def __init__(self, num_strips=(1, 3), strip_width=84, always_apply=False, p=0.5):\n",
    "        super(RandomHorizontalStrips, self).__init__(always_apply, p)\n",
    "        self.num_strips = num_strips\n",
    "        self.strip_width = strip_width\n",
    "\n",
    "    def apply(self, img, **params):\n",
    "        h, w = img.shape[:2]\n",
    "        num_strips = np.random.randint(self.num_strips[0], self.num_strips[1] + 1)\n",
    "        for _ in range(num_strips):\n",
    "            x_start = np.random.randint(0, w - self.strip_width)\n",
    "            img[:, x_start:x_start + self.strip_width] = 0\n",
    "        return img\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return (\"num_strips\", \"strip_width\")\n",
    "\n",
    "    def get_params(self):\n",
    "        return {\"num_strips\": self.num_strips, \"strip_width\": self.strip_width}\n",
    "\n",
    "# 기존의 train_transforms에 새로운 증강 기법 추가\n",
    "train_transforms = A.Compose([\n",
    "    # RandomHorizontalStrips(p=0.5),\n",
    "    A.Resize(height=224, width=224, p=1),\n",
    "    A.GaussNoise(p=0.5),\n",
    "    A.OneOf([\n",
    "        A.GaussianBlur(p=0.5),\n",
    "        A.Sharpen(p=0.5)\n",
    "    ], p=0.5),\n",
    "    A.Normalize(mean=[mean, mean, mean], std=[std, std, std], p=1.0),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "test_transforms = A.Compose([\n",
    "    A.Resize(always_apply = True, p=1.0, height=224, width=224),\n",
    "    A.Normalize(mean=[mean, mean, mean], std=[std, std, std], p=1.0),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_df, train_transforms)\n",
    "valid_dataset = CustomDataset(valid_df, test_transforms)\n",
    "# test_dataset = CustomDataset(test_df, test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = timm.create_model('swinv2_base_window12to24_192to384', pretrained=True, num_classes=7)\n",
    "# # CUDA로 모델 이동\n",
    "# model = model.to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.BCELoss()\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "# scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer, lr_lambda=lambda epoch: 0.95 ** epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def run_model(model, loader, loss_fn=None, optimizer=None, is_training=False, epoch=None):\n",
    "    targets = []\n",
    "    preds = []\n",
    "    smooth_loss_queue = deque(maxlen=50)  # 최근 50개의 손실을 저장할 큐\n",
    "\n",
    "    if is_training:\n",
    "        model.train()\n",
    "        mode = 'Train'\n",
    "    else:\n",
    "        model.eval()\n",
    "        mode = 'Valid/Test'\n",
    "\n",
    "    running_loss = 0.0\n",
    "    bar = tqdm(loader, ascii=True, leave=False)\n",
    "    for cnt, (data, target) in enumerate(bar):\n",
    "        data = data.to('cuda')\n",
    "        target = target.to('cuda')\n",
    "        if is_training:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        outputs = torch.sigmoid(model(data))\n",
    "        total_loss = loss_fn(outputs, target.float())\n",
    "        running_loss += total_loss.item()\n",
    "        smooth_loss_queue.append(total_loss.item())  # 현재 손실을 큐에 추가\n",
    "        smooth_loss = sum(smooth_loss_queue) / len(smooth_loss_queue)  # 큐에 있는 손실의 평균 계산\n",
    "\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        preds.extend(predicted.detach().cpu().tolist())\n",
    "        targets.extend(target.detach().cpu().tolist())\n",
    "\n",
    "        if is_training:\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # 에폭 정보와 함께 배치별 손실 평균 및 smooth loss 출력\n",
    "        bar.set_description(f'Epoch {epoch} {mode} - Loss: {total_loss:.4f}, Smooth Loss: {smooth_loss:.4f}')\n",
    "\n",
    "    f1_score_ = f1_score(np.array(targets), np.array(preds), average='macro')\n",
    "    acc_score = accuracy_score(np.array(targets).reshape(-1), np.array(preds).reshape(-1))\n",
    "\n",
    "    return running_loss / len(loader), acc_score, f1_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_score = -float('inf')\n",
    "\n",
    "# # Initialization list for train visualization\n",
    "# train_per_loss = []\n",
    "# valid_per_loss = []\n",
    "\n",
    "# train_per_acc = []\n",
    "# valid_per_acc = []\n",
    "\n",
    "# train_per_f1 = []\n",
    "# valid_per_f1 = []\n",
    "\n",
    "# history_file = open(\"history.txt\", \"w\")\n",
    "\n",
    "# # Print table header\n",
    "\n",
    "# with open(\"new_Bmodel_aug+.csv\", \"w\", newline='') as csvfile:\n",
    "#     fieldnames = ['Epoch', 'Train Loss', 'Train Acc', 'Train F1', 'Valid Loss', 'Valid Acc', 'Valid F1', 'Learning Rate']\n",
    "#     writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "#     # Write the header\n",
    "#     writer.writeheader()\n",
    "#     for e in range(epochs):\n",
    "#         train_loss, train_acc, train_f1 = run_model(model, train_loader, criterion, optimizer, is_training=True, epoch=e)\n",
    "#         valid_loss, valid_acc, valid_f1 = run_model(model, valid_loader, criterion, optimizer, is_training=False, epoch=e)\n",
    "        \n",
    "#         train_per_loss.append(train_loss)\n",
    "#         valid_per_loss.append(valid_loss)\n",
    "        \n",
    "#         train_per_acc.append(train_acc)\n",
    "#         valid_per_acc.append(valid_acc)\n",
    "        \n",
    "#         train_per_f1.append(train_f1)\n",
    "#         valid_per_f1.append(valid_f1)\n",
    "        \n",
    "#         # Print epoch results in table format\n",
    "#         print(f'{\"-\"*75}')\n",
    "#         print_output = f'Epoch: {e} | Train Loss: {train_loss:.6f} | Train Acc: {train_acc:.6f} | Train F1: {train_f1:.6f} | Valid Loss: {valid_loss:.6f} | Valid Acc: {valid_acc:.6f} | Valid F1: {valid_f1:.6f} | LR: {optimizer.param_groups[0][\"lr\"]:.2e}'\n",
    "#         print(print_output)\n",
    "#         print(f'{\"-\"*75}')\n",
    "#         writer.writerow({\n",
    "#             'Epoch': e,\n",
    "#             'Train Loss': train_loss,\n",
    "#             'Train Acc': train_acc,\n",
    "#             'Train F1': train_f1,\n",
    "#             'Valid Loss': valid_loss,\n",
    "#             'Valid Acc': valid_acc,\n",
    "#             'Valid F1': valid_f1,\n",
    "#             'Learning Rate': optimizer.param_groups[0]['lr']\n",
    "#         })\n",
    "        \n",
    "#         scheduler.step()\n",
    "\n",
    "#         if valid_f1 > best_score:\n",
    "#             print(f'{\"*\"*75}\\nModel saved! Improved from {best_score:.6f} to {valid_f1:.6f}\\n{\"*\"*75}')\n",
    "#             best_score = valid_f1\n",
    "#             torch.save(model.state_dict(), 'models/base_image_aug+.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_df = pd.read_csv('../../../origin_datasets/val_label.csv')\n",
    "# full_df['data_path'] = full_df.apply(lambda row: f\"../new_image_dataset/user{row['subject_id']}_{row['date']}_valid.png\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv('/home/hdd1/ICTC2024/huni_code/val_label.csv')\n",
    "full_df['data_path'] = full_df.apply(lambda row: f\"/home/hdd1/ICTC2024/huni_code/code/image_si/new_image_dataset/user{row['subject_id']}_{row['date']}_valid.png\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# # 데이터셋 클래스와 변환, 모델, 손실 함수, 최적화 기법을 그대로 사용\n",
    "# # 위 코드에서 정의한 CustomDataset, train_transforms, test_transforms 등을 사용\n",
    "\n",
    "# # 전체 데이터셋 준비\n",
    "# full_dataset = CustomDataset(full_df, train_transforms)  # full_df는 전체 데이터프레임을 나타냅니다.\n",
    "\n",
    "# # KFold 설정\n",
    "# k_folds = 5\n",
    "# kf = KFold(n_splits=k_folds, shuffle=True, random_state=1020)\n",
    "\n",
    "# # K-fold 교차 검증 시작\n",
    "# fold_perf = {}\n",
    "\n",
    "# for fold, (train_idx, valid_idx) in enumerate(kf.split(full_dataset)):\n",
    "#     print(f\"Fold {fold+1}\")\n",
    "    \n",
    "#     # 데이터셋 분할\n",
    "#     train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "#     valid_subsampler = torch.utils.data.SubsetRandomSampler(valid_idx)\n",
    "    \n",
    "#     # 데이터 로더 설정\n",
    "#     train_loader = DataLoader(full_dataset, batch_size=16, sampler=train_subsampler)\n",
    "#     valid_loader = DataLoader(full_dataset, batch_size=16, sampler=valid_subsampler)\n",
    "    \n",
    "#     # 모델 초기화 및 이동\n",
    "#     # model = timm.create_model('resnext101_32x32d', pretrained=True, num_classes=7)\n",
    "#     # model = timm.create_model('seresnet18', pretrained=True, num_classes=7) # 0.40?\n",
    "#     # model = timm.create_model('densenet121', pretrained=True, num_classes=7) # 한 줄로 찍음\n",
    "#     model = timm.create_model('densenet201', pretrained=True, num_classes=7)\n",
    "#     model = model.to('cuda')\n",
    "    \n",
    "#     # 손실 함수, 최적화, 스케줄러 설정\n",
    "#     criterion = nn.BCELoss()\n",
    "#     optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "#     # scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer, lr_lambda=lambda epoch: 0.95 ** epoch)\n",
    "#     # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "#     scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=50, T_mult=1, eta_min=0.00007)\n",
    "    \n",
    "#     best_f1 = -float('inf')  # 이 fold에서 최고 F1-score 초기화\n",
    "#     best_loss = 0\n",
    "#     # 학습 및 검증\n",
    "#     for epoch in range(epochs):\n",
    "#         train_loss, train_acc, train_f1 = run_model(model, train_loader, criterion, optimizer, is_training=True, epoch=epoch)\n",
    "#         valid_loss, valid_acc, valid_f1 = run_model(model, valid_loader, criterion, optimizer, is_training=False, epoch=epoch)\n",
    "#         # print(f'Epoch: {epoch+1} | Train Loss: {train_loss:.6f} | Train Acc: {train_acc:.6f} | Train F1: {train_f1:.6f} | Valid Loss: {valid_loss:.6f} | Valid Acc: {valid_acc:.6f} | Valid F1: {valid_f1:.6f} | LR: {optimizer.param_groups[0][\"lr\"]:.2e}')\n",
    "#         logging.info(f'Epoch: {epoch+1} | Train Loss: {train_loss:.6f} | Train Acc: {train_acc:.6f} | Train F1: {train_f1:.6f} | Valid Loss: {valid_loss:.6f} | Valid Acc: {valid_acc:.6f} | Valid F1: {valid_f1:.6f} | LR: {optimizer.param_groups[0][\"lr\"]:.2e}')\n",
    "#         # F1-score를 기준으로 모델 저장\n",
    "#         if valid_f1 > best_f1:\n",
    "#             logging.info(f'Epoch {epoch}: New best F1-score {valid_f1:.4f} in fold {fold+1}')\n",
    "#             best_f1 = valid_f1\n",
    "#             best_loss = valid_loss\n",
    "#             # print(f'Epoch {epoch}: New best F1-score {valid_f1:.4f} in fold {fold+1}, model saved.')\n",
    "        \n",
    "#         scheduler.step()\n",
    "#     # torch.save(model.state_dict(), f'models/model_fold_{fold}_f1-{best_f1:.3f}_loss-{best_loss:.3f}.pt') /home/hdd1/ICTC2024/huni_code/code/image_si/models\n",
    "#     # torch.save(model.state_dict(), f'/home/hdd1/ICTC2024/huni_code/code/image_si/models/model_fold_{fold}_f1-{best_f1:.3f}_loss-{best_loss:.3f}.pt')\n",
    "#     model_path = f'/path/to/models/model_fold_{fold}_f1-{best_f1:.3f}_loss-{best_loss:.3f}.pt'\n",
    "#     torch.save(model.state_dict(), model_path)\n",
    "#     logging.info(f'Model saved: {model_path}')\n",
    "#     # 각 fold의 성능 기록\n",
    "#     fold_perf[fold] = {\n",
    "#         'train_loss': train_loss,\n",
    "#         'train_acc': train_acc,\n",
    "#         'train_f1': train_f1,\n",
    "#         'valid_loss': valid_loss,\n",
    "#         'valid_acc': valid_acc,\n",
    "#         'valid_f1': valid_f1\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf18562493e94e1196a436473799d9d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/196M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import BCELoss\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import KFold\n",
    "import timm\n",
    "\n",
    "# Configure logging\n",
    "log_path = '/home/hdd1/ICTC2024/huni_code/code/image_si/models/logs/seresnext101_32x4d.log'\n",
    "logging.basicConfig(filename=log_path, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# 전체 데이터셋 준비\n",
    "full_dataset = CustomDataset(full_df, train_transforms)  # full_df는 전체 데이터프레임을 나타냅니다.\n",
    "\n",
    "# KFold 설정\n",
    "k_folds = 5\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=1020)\n",
    "\n",
    "# K-fold 교차 검증 시작\n",
    "fold_perf = {}\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(full_dataset)):\n",
    "    logging.info(f\"Starting Fold {fold+1}\")\n",
    "    \n",
    "    # 데이터셋 분할\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    valid_subsampler = torch.utils.data.SubsetRandomSampler(valid_idx)\n",
    "    \n",
    "    # 데이터 로더 설정\n",
    "    train_loader = DataLoader(full_dataset, batch_size=16, sampler=train_subsampler)\n",
    "    valid_loader = DataLoader(full_dataset, batch_size=16, sampler=valid_subsampler)\n",
    "    \n",
    "    # 모델 초기화 및 이동\n",
    "    # model = timm.create_model('densenet201', pretrained=True, num_classes=7)\n",
    "    model = timm.create_model('seresnext101_32x4d', pretrained=True, num_classes=7)\n",
    "    model = model.to('cuda')\n",
    "    \n",
    "    # 손실 함수, 최적화, 스케줄러 설정\n",
    "    criterion = BCELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=50, T_mult=1, eta_min=0.00007)\n",
    "    \n",
    "    best_f1 = -float('inf')\n",
    "    best_loss = 0\n",
    "\n",
    "    # 학습 및 검증\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc, train_f1 = run_model(model, train_loader, criterion, optimizer, is_training=True, epoch=epoch)\n",
    "        valid_loss, valid_acc, valid_f1 = run_model(model, valid_loader, criterion, optimizer, is_training=False, epoch=epoch)\n",
    "        \n",
    "        logging.info(f'Epoch {epoch+1}: Train Loss: {train_loss:.6f}, Train Acc: {train_acc:.6f}, Train F1: {train_f1:.6f}, Valid Loss: {valid_loss:.6f}, Valid Acc: {valid_acc:.6f}, Valid F1: {valid_f1:.6f}')\n",
    "        \n",
    "        if valid_f1 > best_f1:\n",
    "            best_f1 = valid_f1\n",
    "            best_loss = valid_loss\n",
    "            model_path = f'/home/hdd1/ICTC2024/huni_code/code/image_si/models/model_fold_{fold}_f1-{best_f1:.3f}_loss-{best_loss:.3f}_seresnext101_32x4d.pt'\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            logging.info(f'New best F1-score {valid_f1:.4f} achieved at epoch {epoch}, model saved at {model_path}')\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    # 각 fold의 성능 기록\n",
    "    fold_perf[fold] = {\n",
    "        'train_loss': train_loss,\n",
    "        'train_acc': train_acc,\n",
    "        'train_f1': train_f1,\n",
    "        'valid_loss': valid_loss,\n",
    "        'valid_acc': valid_acc,\n",
    "        'valid_f1': valid_f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bat_resnext26ts\n",
      "beit_base_patch16_224\n",
      "beit_base_patch16_384\n",
      "beit_large_patch16_224\n",
      "beit_large_patch16_384\n",
      "beit_large_patch16_512\n",
      "beitv2_base_patch16_224\n",
      "beitv2_large_patch16_224\n",
      "botnet26t_256\n",
      "botnet50ts_256\n",
      "caformer_b36\n",
      "caformer_m36\n",
      "caformer_s18\n",
      "caformer_s36\n",
      "cait_m36_384\n",
      "cait_m48_448\n",
      "cait_s24_224\n",
      "cait_s24_384\n",
      "cait_s36_384\n",
      "cait_xs24_384\n",
      "cait_xxs24_224\n",
      "cait_xxs24_384\n",
      "cait_xxs36_224\n",
      "cait_xxs36_384\n",
      "coat_lite_medium\n",
      "coat_lite_medium_384\n",
      "coat_lite_mini\n",
      "coat_lite_small\n",
      "coat_lite_tiny\n",
      "coat_mini\n",
      "coat_small\n",
      "coat_tiny\n",
      "coatnet_0_224\n",
      "coatnet_0_rw_224\n",
      "coatnet_1_224\n",
      "coatnet_1_rw_224\n",
      "coatnet_2_224\n",
      "coatnet_2_rw_224\n",
      "coatnet_3_224\n",
      "coatnet_3_rw_224\n",
      "coatnet_4_224\n",
      "coatnet_5_224\n",
      "coatnet_bn_0_rw_224\n",
      "coatnet_nano_cc_224\n",
      "coatnet_nano_rw_224\n",
      "coatnet_pico_rw_224\n",
      "coatnet_rmlp_0_rw_224\n",
      "coatnet_rmlp_1_rw2_224\n",
      "coatnet_rmlp_1_rw_224\n",
      "coatnet_rmlp_2_rw_224\n",
      "coatnet_rmlp_2_rw_384\n",
      "coatnet_rmlp_3_rw_224\n",
      "coatnet_rmlp_nano_rw_224\n",
      "coatnext_nano_rw_224\n",
      "convformer_b36\n",
      "convformer_m36\n",
      "convformer_s18\n",
      "convformer_s36\n",
      "convit_base\n",
      "convit_small\n",
      "convit_tiny\n",
      "convmixer_768_32\n",
      "convmixer_1024_20_ks9_p14\n",
      "convmixer_1536_20\n",
      "convnext_atto\n",
      "convnext_atto_ols\n",
      "convnext_base\n",
      "convnext_femto\n",
      "convnext_femto_ols\n",
      "convnext_large\n",
      "convnext_large_mlp\n",
      "convnext_nano\n",
      "convnext_nano_ols\n",
      "convnext_pico\n",
      "convnext_pico_ols\n",
      "convnext_small\n",
      "convnext_tiny\n",
      "convnext_tiny_hnf\n",
      "convnext_xlarge\n",
      "convnext_xxlarge\n",
      "convnextv2_atto\n",
      "convnextv2_base\n",
      "convnextv2_femto\n",
      "convnextv2_huge\n",
      "convnextv2_large\n",
      "convnextv2_nano\n",
      "convnextv2_pico\n",
      "convnextv2_small\n",
      "convnextv2_tiny\n",
      "crossvit_9_240\n",
      "crossvit_9_dagger_240\n",
      "crossvit_15_240\n",
      "crossvit_15_dagger_240\n",
      "crossvit_15_dagger_408\n",
      "crossvit_18_240\n",
      "crossvit_18_dagger_240\n",
      "crossvit_18_dagger_408\n",
      "crossvit_base_240\n",
      "crossvit_small_240\n",
      "crossvit_tiny_240\n",
      "cs3darknet_focus_l\n",
      "cs3darknet_focus_m\n",
      "cs3darknet_focus_s\n",
      "cs3darknet_focus_x\n",
      "cs3darknet_l\n",
      "cs3darknet_m\n",
      "cs3darknet_s\n",
      "cs3darknet_x\n",
      "cs3edgenet_x\n",
      "cs3se_edgenet_x\n",
      "cs3sedarknet_l\n",
      "cs3sedarknet_x\n",
      "cs3sedarknet_xdw\n",
      "cspdarknet53\n",
      "cspresnet50\n",
      "cspresnet50d\n",
      "cspresnet50w\n",
      "cspresnext50\n",
      "darknet17\n",
      "darknet21\n",
      "darknet53\n",
      "darknetaa53\n",
      "davit_base\n",
      "davit_giant\n",
      "davit_huge\n",
      "davit_large\n",
      "davit_small\n",
      "davit_tiny\n",
      "deit3_base_patch16_224\n",
      "deit3_base_patch16_384\n",
      "deit3_huge_patch14_224\n",
      "deit3_large_patch16_224\n",
      "deit3_large_patch16_384\n",
      "deit3_medium_patch16_224\n",
      "deit3_small_patch16_224\n",
      "deit3_small_patch16_384\n",
      "deit_base_distilled_patch16_224\n",
      "deit_base_distilled_patch16_384\n",
      "deit_base_patch16_224\n",
      "deit_base_patch16_384\n",
      "deit_small_distilled_patch16_224\n",
      "deit_small_patch16_224\n",
      "deit_tiny_distilled_patch16_224\n",
      "deit_tiny_patch16_224\n",
      "densenet121\n",
      "densenet161\n",
      "densenet169\n",
      "densenet201\n",
      "densenet264d\n",
      "densenetblur121d\n",
      "dla34\n",
      "dla46_c\n",
      "dla46x_c\n",
      "dla60\n",
      "dla60_res2net\n",
      "dla60_res2next\n",
      "dla60x\n",
      "dla60x_c\n",
      "dla102\n",
      "dla102x\n",
      "dla102x2\n",
      "dla169\n",
      "dm_nfnet_f0\n",
      "dm_nfnet_f1\n",
      "dm_nfnet_f2\n",
      "dm_nfnet_f3\n",
      "dm_nfnet_f4\n",
      "dm_nfnet_f5\n",
      "dm_nfnet_f6\n",
      "dpn48b\n",
      "dpn68\n",
      "dpn68b\n",
      "dpn92\n",
      "dpn98\n",
      "dpn107\n",
      "dpn131\n",
      "eca_botnext26ts_256\n",
      "eca_halonext26ts\n",
      "eca_nfnet_l0\n",
      "eca_nfnet_l1\n",
      "eca_nfnet_l2\n",
      "eca_nfnet_l3\n",
      "eca_resnet33ts\n",
      "eca_resnext26ts\n",
      "eca_vovnet39b\n",
      "ecaresnet26t\n",
      "ecaresnet50d\n",
      "ecaresnet50d_pruned\n",
      "ecaresnet50t\n",
      "ecaresnet101d\n",
      "ecaresnet101d_pruned\n",
      "ecaresnet200d\n",
      "ecaresnet269d\n",
      "ecaresnetlight\n",
      "ecaresnext26t_32x4d\n",
      "ecaresnext50t_32x4d\n",
      "edgenext_base\n",
      "edgenext_small\n",
      "edgenext_small_rw\n",
      "edgenext_x_small\n",
      "edgenext_xx_small\n",
      "efficientformer_l1\n",
      "efficientformer_l3\n",
      "efficientformer_l7\n",
      "efficientformerv2_l\n",
      "efficientformerv2_s0\n",
      "efficientformerv2_s1\n",
      "efficientformerv2_s2\n",
      "efficientnet_b0\n",
      "efficientnet_b0_g8_gn\n",
      "efficientnet_b0_g16_evos\n",
      "efficientnet_b0_gn\n",
      "efficientnet_b1\n",
      "efficientnet_b1_pruned\n",
      "efficientnet_b2\n",
      "efficientnet_b2_pruned\n",
      "efficientnet_b2a\n",
      "efficientnet_b3\n",
      "efficientnet_b3_g8_gn\n",
      "efficientnet_b3_gn\n",
      "efficientnet_b3_pruned\n",
      "efficientnet_b3a\n",
      "efficientnet_b4\n",
      "efficientnet_b5\n",
      "efficientnet_b6\n",
      "efficientnet_b7\n",
      "efficientnet_b8\n",
      "efficientnet_cc_b0_4e\n",
      "efficientnet_cc_b0_8e\n",
      "efficientnet_cc_b1_8e\n",
      "efficientnet_el\n",
      "efficientnet_el_pruned\n",
      "efficientnet_em\n",
      "efficientnet_es\n",
      "efficientnet_es_pruned\n",
      "efficientnet_l2\n",
      "efficientnet_lite0\n",
      "efficientnet_lite1\n",
      "efficientnet_lite2\n",
      "efficientnet_lite3\n",
      "efficientnet_lite4\n",
      "efficientnetv2_l\n",
      "efficientnetv2_m\n",
      "efficientnetv2_rw_m\n",
      "efficientnetv2_rw_s\n",
      "efficientnetv2_rw_t\n",
      "efficientnetv2_s\n",
      "efficientnetv2_xl\n",
      "ese_vovnet19b_dw\n",
      "ese_vovnet19b_slim\n",
      "ese_vovnet19b_slim_dw\n",
      "ese_vovnet39b\n",
      "ese_vovnet39b_evos\n",
      "ese_vovnet57b\n",
      "ese_vovnet99b\n",
      "eva02_base_patch14_224\n",
      "eva02_base_patch14_448\n",
      "eva02_base_patch16_clip_224\n",
      "eva02_enormous_patch14_clip_224\n",
      "eva02_large_patch14_224\n",
      "eva02_large_patch14_448\n",
      "eva02_large_patch14_clip_224\n",
      "eva02_large_patch14_clip_336\n",
      "eva02_small_patch14_224\n",
      "eva02_small_patch14_336\n",
      "eva02_tiny_patch14_224\n",
      "eva02_tiny_patch14_336\n",
      "eva_giant_patch14_224\n",
      "eva_giant_patch14_336\n",
      "eva_giant_patch14_560\n",
      "eva_giant_patch14_clip_224\n",
      "eva_large_patch14_196\n",
      "eva_large_patch14_336\n",
      "fbnetc_100\n",
      "fbnetv3_b\n",
      "fbnetv3_d\n",
      "fbnetv3_g\n",
      "flexivit_base\n",
      "flexivit_large\n",
      "flexivit_small\n",
      "focalnet_base_lrf\n",
      "focalnet_base_srf\n",
      "focalnet_huge_fl3\n",
      "focalnet_huge_fl4\n",
      "focalnet_large_fl3\n",
      "focalnet_large_fl4\n",
      "focalnet_small_lrf\n",
      "focalnet_small_srf\n",
      "focalnet_tiny_lrf\n",
      "focalnet_tiny_srf\n",
      "focalnet_xlarge_fl3\n",
      "focalnet_xlarge_fl4\n",
      "gc_efficientnetv2_rw_t\n",
      "gcresnet33ts\n",
      "gcresnet50t\n",
      "gcresnext26ts\n",
      "gcresnext50ts\n",
      "gcvit_base\n",
      "gcvit_small\n",
      "gcvit_tiny\n",
      "gcvit_xtiny\n",
      "gcvit_xxtiny\n",
      "gernet_l\n",
      "gernet_m\n",
      "gernet_s\n",
      "ghostnet_050\n",
      "ghostnet_100\n",
      "ghostnet_130\n",
      "gmixer_12_224\n",
      "gmixer_24_224\n",
      "gmlp_b16_224\n",
      "gmlp_s16_224\n",
      "gmlp_ti16_224\n",
      "halo2botnet50ts_256\n",
      "halonet26t\n",
      "halonet50ts\n",
      "halonet_h1\n",
      "haloregnetz_b\n",
      "hardcorenas_a\n",
      "hardcorenas_b\n",
      "hardcorenas_c\n",
      "hardcorenas_d\n",
      "hardcorenas_e\n",
      "hardcorenas_f\n",
      "hrnet_w18\n",
      "hrnet_w18_small\n",
      "hrnet_w18_small_v2\n",
      "hrnet_w18_ssld\n",
      "hrnet_w30\n",
      "hrnet_w32\n",
      "hrnet_w40\n",
      "hrnet_w44\n",
      "hrnet_w48\n",
      "hrnet_w48_ssld\n",
      "hrnet_w64\n",
      "inception_resnet_v2\n",
      "inception_v3\n",
      "inception_v4\n",
      "lambda_resnet26rpt_256\n",
      "lambda_resnet26t\n",
      "lambda_resnet50ts\n",
      "lamhalobotnet50ts_256\n",
      "lcnet_035\n",
      "lcnet_050\n",
      "lcnet_075\n",
      "lcnet_100\n",
      "lcnet_150\n",
      "legacy_senet154\n",
      "legacy_seresnet18\n",
      "legacy_seresnet34\n",
      "legacy_seresnet50\n",
      "legacy_seresnet101\n",
      "legacy_seresnet152\n",
      "legacy_seresnext26_32x4d\n",
      "legacy_seresnext50_32x4d\n",
      "legacy_seresnext101_32x4d\n",
      "legacy_xception\n",
      "levit_128\n",
      "levit_128s\n",
      "levit_192\n",
      "levit_256\n",
      "levit_256d\n",
      "levit_384\n",
      "levit_384_s8\n",
      "levit_512\n",
      "levit_512_s8\n",
      "levit_512d\n",
      "levit_conv_128\n",
      "levit_conv_128s\n",
      "levit_conv_192\n",
      "levit_conv_256\n",
      "levit_conv_256d\n",
      "levit_conv_384\n",
      "levit_conv_384_s8\n",
      "levit_conv_512\n",
      "levit_conv_512_s8\n",
      "levit_conv_512d\n",
      "maxvit_base_tf_224\n",
      "maxvit_base_tf_384\n",
      "maxvit_base_tf_512\n",
      "maxvit_large_tf_224\n",
      "maxvit_large_tf_384\n",
      "maxvit_large_tf_512\n",
      "maxvit_nano_rw_256\n",
      "maxvit_pico_rw_256\n",
      "maxvit_rmlp_base_rw_224\n",
      "maxvit_rmlp_base_rw_384\n",
      "maxvit_rmlp_nano_rw_256\n",
      "maxvit_rmlp_pico_rw_256\n",
      "maxvit_rmlp_small_rw_224\n",
      "maxvit_rmlp_small_rw_256\n",
      "maxvit_rmlp_tiny_rw_256\n",
      "maxvit_small_tf_224\n",
      "maxvit_small_tf_384\n",
      "maxvit_small_tf_512\n",
      "maxvit_tiny_pm_256\n",
      "maxvit_tiny_rw_224\n",
      "maxvit_tiny_rw_256\n",
      "maxvit_tiny_tf_224\n",
      "maxvit_tiny_tf_384\n",
      "maxvit_tiny_tf_512\n",
      "maxvit_xlarge_tf_224\n",
      "maxvit_xlarge_tf_384\n",
      "maxvit_xlarge_tf_512\n",
      "maxxvit_rmlp_nano_rw_256\n",
      "maxxvit_rmlp_small_rw_256\n",
      "maxxvit_rmlp_tiny_rw_256\n",
      "maxxvitv2_nano_rw_256\n",
      "maxxvitv2_rmlp_base_rw_224\n",
      "maxxvitv2_rmlp_base_rw_384\n",
      "maxxvitv2_rmlp_large_rw_224\n",
      "mixer_b16_224\n",
      "mixer_b32_224\n",
      "mixer_l16_224\n",
      "mixer_l32_224\n",
      "mixer_s16_224\n",
      "mixer_s32_224\n",
      "mixnet_l\n",
      "mixnet_m\n",
      "mixnet_s\n",
      "mixnet_xl\n",
      "mixnet_xxl\n",
      "mnasnet_050\n",
      "mnasnet_075\n",
      "mnasnet_100\n",
      "mnasnet_140\n",
      "mnasnet_a1\n",
      "mnasnet_b1\n",
      "mnasnet_small\n",
      "mobilenetv2_035\n",
      "mobilenetv2_050\n",
      "mobilenetv2_075\n",
      "mobilenetv2_100\n",
      "mobilenetv2_110d\n",
      "mobilenetv2_120d\n",
      "mobilenetv2_140\n",
      "mobilenetv3_large_075\n",
      "mobilenetv3_large_100\n",
      "mobilenetv3_rw\n",
      "mobilenetv3_small_050\n",
      "mobilenetv3_small_075\n",
      "mobilenetv3_small_100\n",
      "mobilevit_s\n",
      "mobilevit_xs\n",
      "mobilevit_xxs\n",
      "mobilevitv2_050\n",
      "mobilevitv2_075\n",
      "mobilevitv2_100\n",
      "mobilevitv2_125\n",
      "mobilevitv2_150\n",
      "mobilevitv2_175\n",
      "mobilevitv2_200\n",
      "mvitv2_base\n",
      "mvitv2_base_cls\n",
      "mvitv2_huge_cls\n",
      "mvitv2_large\n",
      "mvitv2_large_cls\n",
      "mvitv2_small\n",
      "mvitv2_small_cls\n",
      "mvitv2_tiny\n",
      "nasnetalarge\n",
      "nest_base\n",
      "nest_base_jx\n",
      "nest_small\n",
      "nest_small_jx\n",
      "nest_tiny\n",
      "nest_tiny_jx\n",
      "nf_ecaresnet26\n",
      "nf_ecaresnet50\n",
      "nf_ecaresnet101\n",
      "nf_regnet_b0\n",
      "nf_regnet_b1\n",
      "nf_regnet_b2\n",
      "nf_regnet_b3\n",
      "nf_regnet_b4\n",
      "nf_regnet_b5\n",
      "nf_resnet26\n",
      "nf_resnet50\n",
      "nf_resnet101\n",
      "nf_seresnet26\n",
      "nf_seresnet50\n",
      "nf_seresnet101\n",
      "nfnet_f0\n",
      "nfnet_f1\n",
      "nfnet_f2\n",
      "nfnet_f3\n",
      "nfnet_f4\n",
      "nfnet_f5\n",
      "nfnet_f6\n",
      "nfnet_f7\n",
      "nfnet_l0\n",
      "pit_b_224\n",
      "pit_b_distilled_224\n",
      "pit_s_224\n",
      "pit_s_distilled_224\n",
      "pit_ti_224\n",
      "pit_ti_distilled_224\n",
      "pit_xs_224\n",
      "pit_xs_distilled_224\n",
      "pnasnet5large\n",
      "poolformer_m36\n",
      "poolformer_m48\n",
      "poolformer_s12\n",
      "poolformer_s24\n",
      "poolformer_s36\n",
      "poolformerv2_m36\n",
      "poolformerv2_m48\n",
      "poolformerv2_s12\n",
      "poolformerv2_s24\n",
      "poolformerv2_s36\n",
      "pvt_v2_b0\n",
      "pvt_v2_b1\n",
      "pvt_v2_b2\n",
      "pvt_v2_b2_li\n",
      "pvt_v2_b3\n",
      "pvt_v2_b4\n",
      "pvt_v2_b5\n",
      "regnetv_040\n",
      "regnetv_064\n",
      "regnetx_002\n",
      "regnetx_004\n",
      "regnetx_004_tv\n",
      "regnetx_006\n",
      "regnetx_008\n",
      "regnetx_016\n",
      "regnetx_032\n",
      "regnetx_040\n",
      "regnetx_064\n",
      "regnetx_080\n",
      "regnetx_120\n",
      "regnetx_160\n",
      "regnetx_320\n",
      "regnety_002\n",
      "regnety_004\n",
      "regnety_006\n",
      "regnety_008\n",
      "regnety_008_tv\n",
      "regnety_016\n",
      "regnety_032\n",
      "regnety_040\n",
      "regnety_040_sgn\n",
      "regnety_064\n",
      "regnety_080\n",
      "regnety_080_tv\n",
      "regnety_120\n",
      "regnety_160\n",
      "regnety_320\n",
      "regnety_640\n",
      "regnety_1280\n",
      "regnety_2560\n",
      "regnetz_005\n",
      "regnetz_040\n",
      "regnetz_040_h\n",
      "regnetz_b16\n",
      "regnetz_b16_evos\n",
      "regnetz_c16\n",
      "regnetz_c16_evos\n",
      "regnetz_d8\n",
      "regnetz_d8_evos\n",
      "regnetz_d32\n",
      "regnetz_e8\n",
      "repvgg_a2\n",
      "repvgg_b0\n",
      "repvgg_b1\n",
      "repvgg_b1g4\n",
      "repvgg_b2\n",
      "repvgg_b2g4\n",
      "repvgg_b3\n",
      "repvgg_b3g4\n",
      "res2net50_14w_8s\n",
      "res2net50_26w_4s\n",
      "res2net50_26w_6s\n",
      "res2net50_26w_8s\n",
      "res2net50_48w_2s\n",
      "res2net50d\n",
      "res2net101_26w_4s\n",
      "res2net101d\n",
      "res2next50\n",
      "resmlp_12_224\n",
      "resmlp_24_224\n",
      "resmlp_36_224\n",
      "resmlp_big_24_224\n",
      "resnest14d\n",
      "resnest26d\n",
      "resnest50d\n",
      "resnest50d_1s4x24d\n",
      "resnest50d_4s2x40d\n",
      "resnest101e\n",
      "resnest200e\n",
      "resnest269e\n",
      "resnet10t\n",
      "resnet14t\n",
      "resnet18\n",
      "resnet18d\n",
      "resnet26\n",
      "resnet26d\n",
      "resnet26t\n",
      "resnet32ts\n",
      "resnet33ts\n",
      "resnet34\n",
      "resnet34d\n",
      "resnet50\n",
      "resnet50_gn\n",
      "resnet50c\n",
      "resnet50d\n",
      "resnet50s\n",
      "resnet50t\n",
      "resnet51q\n",
      "resnet61q\n",
      "resnet101\n",
      "resnet101c\n",
      "resnet101d\n",
      "resnet101s\n",
      "resnet152\n",
      "resnet152c\n",
      "resnet152d\n",
      "resnet152s\n",
      "resnet200\n",
      "resnet200d\n",
      "resnetaa34d\n",
      "resnetaa50\n",
      "resnetaa50d\n",
      "resnetaa101d\n",
      "resnetblur18\n",
      "resnetblur50\n",
      "resnetblur50d\n",
      "resnetblur101d\n",
      "resnetrs50\n",
      "resnetrs101\n",
      "resnetrs152\n",
      "resnetrs200\n",
      "resnetrs270\n",
      "resnetrs350\n",
      "resnetrs420\n",
      "resnetv2_50\n",
      "resnetv2_50d\n",
      "resnetv2_50d_evos\n",
      "resnetv2_50d_frn\n",
      "resnetv2_50d_gn\n",
      "resnetv2_50t\n",
      "resnetv2_50x1_bit\n",
      "resnetv2_50x3_bit\n",
      "resnetv2_101\n",
      "resnetv2_101d\n",
      "resnetv2_101x1_bit\n",
      "resnetv2_101x3_bit\n",
      "resnetv2_152\n",
      "resnetv2_152d\n",
      "resnetv2_152x2_bit\n",
      "resnetv2_152x4_bit\n",
      "resnext26ts\n",
      "resnext50_32x4d\n",
      "resnext50d_32x4d\n",
      "resnext101_32x4d\n",
      "resnext101_32x8d\n",
      "resnext101_32x16d\n",
      "resnext101_32x32d\n",
      "resnext101_64x4d\n",
      "rexnet_100\n",
      "rexnet_130\n",
      "rexnet_150\n",
      "rexnet_200\n",
      "rexnet_300\n",
      "rexnetr_100\n",
      "rexnetr_130\n",
      "rexnetr_150\n",
      "rexnetr_200\n",
      "rexnetr_300\n",
      "sebotnet33ts_256\n",
      "sedarknet21\n",
      "sehalonet33ts\n",
      "SelecSls42\n",
      "SelecSls42b\n",
      "SelecSls60\n",
      "SelecSls60b\n",
      "SelecSls84\n",
      "semnasnet_050\n",
      "semnasnet_075\n",
      "semnasnet_100\n",
      "semnasnet_140\n",
      "senet154\n",
      "sequencer2d_l\n",
      "sequencer2d_m\n",
      "sequencer2d_s\n",
      "seresnet18\n",
      "seresnet33ts\n",
      "seresnet34\n",
      "seresnet50\n",
      "seresnet50t\n",
      "seresnet101\n",
      "seresnet152\n",
      "seresnet152d\n",
      "seresnet200d\n",
      "seresnet269d\n",
      "seresnetaa50d\n",
      "seresnext26d_32x4d\n",
      "seresnext26t_32x4d\n",
      "seresnext26tn_32x4d\n",
      "seresnext26ts\n",
      "seresnext50_32x4d\n",
      "seresnext101_32x4d\n",
      "seresnext101_32x8d\n",
      "seresnext101_64x4d\n",
      "seresnext101d_32x8d\n",
      "seresnextaa101d_32x8d\n",
      "skresnet18\n",
      "skresnet34\n",
      "skresnet50\n",
      "skresnet50d\n",
      "skresnext50_32x4d\n",
      "spnasnet_100\n",
      "swin_base_patch4_window7_224\n",
      "swin_base_patch4_window12_384\n",
      "swin_large_patch4_window7_224\n",
      "swin_large_patch4_window12_384\n",
      "swin_s3_base_224\n",
      "swin_s3_small_224\n",
      "swin_s3_tiny_224\n",
      "swin_small_patch4_window7_224\n",
      "swin_tiny_patch4_window7_224\n",
      "swinv2_base_window8_256\n",
      "swinv2_base_window12_192\n",
      "swinv2_base_window12to16_192to256\n",
      "swinv2_base_window12to24_192to384\n",
      "swinv2_base_window16_256\n",
      "swinv2_cr_base_224\n",
      "swinv2_cr_base_384\n",
      "swinv2_cr_base_ns_224\n",
      "swinv2_cr_giant_224\n",
      "swinv2_cr_giant_384\n",
      "swinv2_cr_huge_224\n",
      "swinv2_cr_huge_384\n",
      "swinv2_cr_large_224\n",
      "swinv2_cr_large_384\n",
      "swinv2_cr_small_224\n",
      "swinv2_cr_small_384\n",
      "swinv2_cr_small_ns_224\n",
      "swinv2_cr_small_ns_256\n",
      "swinv2_cr_tiny_224\n",
      "swinv2_cr_tiny_384\n",
      "swinv2_cr_tiny_ns_224\n",
      "swinv2_large_window12_192\n",
      "swinv2_large_window12to16_192to256\n",
      "swinv2_large_window12to24_192to384\n",
      "swinv2_small_window8_256\n",
      "swinv2_small_window16_256\n",
      "swinv2_tiny_window8_256\n",
      "swinv2_tiny_window16_256\n",
      "tf_efficientnet_b0\n",
      "tf_efficientnet_b1\n",
      "tf_efficientnet_b2\n",
      "tf_efficientnet_b3\n",
      "tf_efficientnet_b4\n",
      "tf_efficientnet_b5\n",
      "tf_efficientnet_b6\n",
      "tf_efficientnet_b7\n",
      "tf_efficientnet_b8\n",
      "tf_efficientnet_cc_b0_4e\n",
      "tf_efficientnet_cc_b0_8e\n",
      "tf_efficientnet_cc_b1_8e\n",
      "tf_efficientnet_el\n",
      "tf_efficientnet_em\n",
      "tf_efficientnet_es\n",
      "tf_efficientnet_l2\n",
      "tf_efficientnet_lite0\n",
      "tf_efficientnet_lite1\n",
      "tf_efficientnet_lite2\n",
      "tf_efficientnet_lite3\n",
      "tf_efficientnet_lite4\n",
      "tf_efficientnetv2_b0\n",
      "tf_efficientnetv2_b1\n",
      "tf_efficientnetv2_b2\n",
      "tf_efficientnetv2_b3\n",
      "tf_efficientnetv2_l\n",
      "tf_efficientnetv2_m\n",
      "tf_efficientnetv2_s\n",
      "tf_efficientnetv2_xl\n",
      "tf_mixnet_l\n",
      "tf_mixnet_m\n",
      "tf_mixnet_s\n",
      "tf_mobilenetv3_large_075\n",
      "tf_mobilenetv3_large_100\n",
      "tf_mobilenetv3_large_minimal_100\n",
      "tf_mobilenetv3_small_075\n",
      "tf_mobilenetv3_small_100\n",
      "tf_mobilenetv3_small_minimal_100\n",
      "tinynet_a\n",
      "tinynet_b\n",
      "tinynet_c\n",
      "tinynet_d\n",
      "tinynet_e\n",
      "tnt_b_patch16_224\n",
      "tnt_s_patch16_224\n",
      "tresnet_l\n",
      "tresnet_m\n",
      "tresnet_v2_l\n",
      "tresnet_xl\n",
      "twins_pcpvt_base\n",
      "twins_pcpvt_large\n",
      "twins_pcpvt_small\n",
      "twins_svt_base\n",
      "twins_svt_large\n",
      "twins_svt_small\n",
      "vgg11\n",
      "vgg11_bn\n",
      "vgg13\n",
      "vgg13_bn\n",
      "vgg16\n",
      "vgg16_bn\n",
      "vgg19\n",
      "vgg19_bn\n",
      "visformer_small\n",
      "visformer_tiny\n",
      "vit_base_patch8_224\n",
      "vit_base_patch14_dinov2\n",
      "vit_base_patch16_18x2_224\n",
      "vit_base_patch16_224\n",
      "vit_base_patch16_224_miil\n",
      "vit_base_patch16_384\n",
      "vit_base_patch16_clip_224\n",
      "vit_base_patch16_clip_384\n",
      "vit_base_patch16_gap_224\n",
      "vit_base_patch16_plus_240\n",
      "vit_base_patch16_rpn_224\n",
      "vit_base_patch16_xp_224\n",
      "vit_base_patch32_224\n",
      "vit_base_patch32_384\n",
      "vit_base_patch32_clip_224\n",
      "vit_base_patch32_clip_384\n",
      "vit_base_patch32_clip_448\n",
      "vit_base_patch32_plus_256\n",
      "vit_base_r26_s32_224\n",
      "vit_base_r50_s16_224\n",
      "vit_base_r50_s16_384\n",
      "vit_base_resnet26d_224\n",
      "vit_base_resnet50d_224\n",
      "vit_giant_patch14_224\n",
      "vit_giant_patch14_clip_224\n",
      "vit_giant_patch14_dinov2\n",
      "vit_gigantic_patch14_224\n",
      "vit_gigantic_patch14_clip_224\n",
      "vit_huge_patch14_224\n",
      "vit_huge_patch14_clip_224\n",
      "vit_huge_patch14_clip_336\n",
      "vit_huge_patch14_xp_224\n",
      "vit_large_patch14_224\n",
      "vit_large_patch14_clip_224\n",
      "vit_large_patch14_clip_336\n",
      "vit_large_patch14_dinov2\n",
      "vit_large_patch14_xp_224\n",
      "vit_large_patch16_224\n",
      "vit_large_patch16_384\n",
      "vit_large_patch32_224\n",
      "vit_large_patch32_384\n",
      "vit_large_r50_s32_224\n",
      "vit_large_r50_s32_384\n",
      "vit_medium_patch16_gap_240\n",
      "vit_medium_patch16_gap_256\n",
      "vit_medium_patch16_gap_384\n",
      "vit_relpos_base_patch16_224\n",
      "vit_relpos_base_patch16_cls_224\n",
      "vit_relpos_base_patch16_clsgap_224\n",
      "vit_relpos_base_patch16_plus_240\n",
      "vit_relpos_base_patch16_rpn_224\n",
      "vit_relpos_base_patch32_plus_rpn_256\n",
      "vit_relpos_medium_patch16_224\n",
      "vit_relpos_medium_patch16_cls_224\n",
      "vit_relpos_medium_patch16_rpn_224\n",
      "vit_relpos_small_patch16_224\n",
      "vit_relpos_small_patch16_rpn_224\n",
      "vit_small_patch8_224\n",
      "vit_small_patch14_dinov2\n",
      "vit_small_patch16_18x2_224\n",
      "vit_small_patch16_36x1_224\n",
      "vit_small_patch16_224\n",
      "vit_small_patch16_384\n",
      "vit_small_patch32_224\n",
      "vit_small_patch32_384\n",
      "vit_small_r26_s32_224\n",
      "vit_small_r26_s32_384\n",
      "vit_small_resnet26d_224\n",
      "vit_small_resnet50d_s16_224\n",
      "vit_srelpos_medium_patch16_224\n",
      "vit_srelpos_small_patch16_224\n",
      "vit_tiny_patch16_224\n",
      "vit_tiny_patch16_384\n",
      "vit_tiny_r_s16_p8_224\n",
      "vit_tiny_r_s16_p8_384\n",
      "volo_d1_224\n",
      "volo_d1_384\n",
      "volo_d2_224\n",
      "volo_d2_384\n",
      "volo_d3_224\n",
      "volo_d3_448\n",
      "volo_d4_224\n",
      "volo_d4_448\n",
      "volo_d5_224\n",
      "volo_d5_448\n",
      "volo_d5_512\n",
      "vovnet39a\n",
      "vovnet57a\n",
      "wide_resnet50_2\n",
      "wide_resnet101_2\n",
      "xception41\n",
      "xception41p\n",
      "xception65\n",
      "xception65p\n",
      "xception71\n",
      "xcit_large_24_p8_224\n",
      "xcit_large_24_p8_384\n",
      "xcit_large_24_p16_224\n",
      "xcit_large_24_p16_384\n",
      "xcit_medium_24_p8_224\n",
      "xcit_medium_24_p8_384\n",
      "xcit_medium_24_p16_224\n",
      "xcit_medium_24_p16_384\n",
      "xcit_nano_12_p8_224\n",
      "xcit_nano_12_p8_384\n",
      "xcit_nano_12_p16_224\n",
      "xcit_nano_12_p16_384\n",
      "xcit_small_12_p8_224\n",
      "xcit_small_12_p8_384\n",
      "xcit_small_12_p16_224\n",
      "xcit_small_12_p16_384\n",
      "xcit_small_24_p8_224\n",
      "xcit_small_24_p8_384\n",
      "xcit_small_24_p16_224\n",
      "xcit_small_24_p16_384\n",
      "xcit_tiny_12_p8_224\n",
      "xcit_tiny_12_p8_384\n",
      "xcit_tiny_12_p16_224\n",
      "xcit_tiny_12_p16_384\n",
      "xcit_tiny_24_p8_224\n",
      "xcit_tiny_24_p8_384\n",
      "xcit_tiny_24_p16_224\n",
      "xcit_tiny_24_p16_384\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "resnet_models = timm.list_models()\n",
    "\n",
    "for model_name in resnet_models:\n",
    "    print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.1 (NGC 23.07/Python 3.10) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
