{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.cli import tqdm\n",
    "import re, os, random\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as v2\n",
    "import timm\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)  # Python 내장 random 모듈\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # 환경변수 설정\n",
    "    np.random.seed(seed)  # NumPy\n",
    "    torch.manual_seed(seed)  # PyTorch CPU 시드 고정\n",
    "    torch.cuda.manual_seed(seed)  # PyTorch GPU 시드 고정\n",
    "    torch.cuda.manual_seed_all(seed)  # 멀티 GPU 환경에서도 시드 고정\n",
    "    torch.backends.cudnn.deterministic = True  # CuDNN 관련 설정\n",
    "    torch.backends.cudnn.benchmark = False  # 동일한 입력 크기의 데이터가 반복될 경우 속도 향상을 위한 벤치마크 모드 비활성화\n",
    "\n",
    "# 사용 예시\n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 경로 포함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 mean, std 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "test_transforms = A.Compose([\n",
    "    A.Resize(always_apply = True, p=1.0, height=224, width=224),\n",
    "    A.Normalize(p=1.0),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.read_csv('../../../origin_datasets/answer_sample.csv')\n",
    "test_df = pd.read_csv('datasets/answer_sample.csv')\n",
    "# test_df['data_path'] = test_df.apply(lambda row: f\"../new_image_dataset/user{row['subject_id']}_{row['date']}_test.png\", axis=1)\n",
    "test_df['data_path'] = test_df.apply(lambda row: f\"datasets/image_datasets/test_images/user{row['subject_id']}_{row['date']}_org.png\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transforms):\n",
    "        self.path = df['data_path'].values\n",
    "        self.transform = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img = np.array(Image.open(self.path[idx]).convert('RGB'))\n",
    "        except FileNotFoundError:\n",
    "            # If file not found, skip to the next item\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "        \n",
    "        img = self.transform(image=img)\n",
    "        img = img[\"image\"]\n",
    "        \n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test_df, test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = timm.create_model('deit3_large_patch16_384', pretrained=False, num_classes=7)\n",
    "# checkpoint = torch.load(f'models/model_fold_0_best.pt')\n",
    "# model.load_state_dict(checkpoint)\n",
    "# model = model.to('cuda')\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(model, test_loader, device):\n",
    "#     model.eval()\n",
    "#     model_pred = []\n",
    "#     with torch.no_grad():\n",
    "#         for data in tqdm(iter(test_loader)):\n",
    "#             data = data.to(device)\n",
    "#             pred = model(data)  # Get raw model predictions\n",
    "#             pred = torch.sigmoid(pred)\n",
    "#             model_pred.extend(pred.cpu().tolist())  # Append predictions to the list\n",
    "\n",
    "#     return model_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 15/15 [00:03<00:00,  4.65it/s]\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "from glob import glob\n",
    "\n",
    "for fold in glob('result/*'): # 5.88 change q3 --> 6.28\n",
    "    if 'fold_1' in fold or 'fold_2' in fold: continue\n",
    "    model = timm.create_model('seresnext101_32x4d', pretrained=False, num_classes=7)\n",
    "    checkpoint = torch.load(f'{fold[:-3]}.pt')\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model = model.to('cuda')\n",
    "    model.eval()\n",
    "    models.append(model)\n",
    "\n",
    "def predict_ensemble(models, test_loader, device):\n",
    "    model_preds = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(iter(test_loader)):\n",
    "            data = data.to(device)\n",
    "            fold_preds = []\n",
    "            for model in models:\n",
    "                pred = model(data)  # Get raw model predictions\n",
    "                pred = torch.sigmoid(pred)\n",
    "                fold_preds.append(pred.cpu().numpy())\n",
    "            # 평균을 통해 soft voting\n",
    "            fold_preds = np.mean(fold_preds, axis=0)\n",
    "            model_preds.extend(fold_preds)\n",
    "    return model_preds\n",
    "\n",
    "preds = np.array(predict_ensemble(models, test_loader, 'cuda'))\n",
    "predictions_df = pd.DataFrame(preds, columns=['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3', 'S4'])\n",
    "\n",
    "def binarize_predictions(predictions, threshold=0.5):\n",
    "    binary_predictions = (predictions > threshold).astype(int)\n",
    "    return binary_predictions\n",
    "\n",
    "binary_preds = binarize_predictions(predictions_df , averages)\n",
    "\n",
    "predictions_df = pd.DataFrame(binary_preds, columns=['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3', 'S4'])\n",
    "\n",
    "# Assuming `test_df` is your original DataFrame with test data\n",
    "final_df = pd.concat([test_df[['subject_id', 'date']], predictions_df], axis=1)\n",
    "\n",
    "# Optionally save or display the DataFrame\n",
    "final_df.to_csv(f\"new_image_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject_id :  subject_id\n",
      "6    33\n",
      "7    33\n",
      "8    29\n",
      "5    20\n",
      "Name: count, dtype: int64\n",
      "Q1 :  Q1\n",
      "0    59\n",
      "1    56\n",
      "Name: count, dtype: int64\n",
      "Q2 :  Q2\n",
      "1    109\n",
      "0      6\n",
      "Name: count, dtype: int64\n",
      "Q3 :  Q3\n",
      "0    76\n",
      "1    39\n",
      "Name: count, dtype: int64\n",
      "S1 :  S1\n",
      "0    98\n",
      "1    17\n",
      "Name: count, dtype: int64\n",
      "S2 :  S2\n",
      "0    78\n",
      "1    37\n",
      "Name: count, dtype: int64\n",
      "S3 :  S3\n",
      "1    80\n",
      "0    35\n",
      "Name: count, dtype: int64\n",
      "S4 :  S4\n",
      "0    80\n",
      "1    35\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in final_df.columns :\n",
    "    if col != 'date':\n",
    "        print(f'{col} :  {final_df[col].value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>date</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2023-11-05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2023-11-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2023-11-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2023-11-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id        date  Q1  Q2  Q3  S1  S2  S3  S4\n",
       "0           5  2023-11-05   0   1   0   1   0   0   0\n",
       "1           5  2023-11-06   1   0   0   1   0   1   0\n",
       "2           5  2023-11-07   1   0   0   0   0   1   0\n",
       "3           5  2023-11-08   0   1   0   1   0   0   0\n",
       "4           5  2023-11-09   0   0   0   0   0   0   0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read = pd.read_csv('binary_predictions1.csv')\n",
    "read.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    subject_id        date  Q1  Q2  Q3  S1  S2  S3  S4\n",
      "0            5  2023-11-05   0   1   0   1   0   0   0\n",
      "1            5  2023-11-06   1   0   0   1   0   1   0\n",
      "2            5  2023-11-07   1   0   0   0   0   1   0\n",
      "3            5  2023-11-08   0   1   0   1   0   0   0\n",
      "4            5  2023-11-09   0   0   0   0   0   0   0\n",
      "5            5  2023-11-10   1   1   0   1   0   0   0\n",
      "6            5  2023-11-11   0   0   0   0   0   1   0\n",
      "7            5  2023-11-12   0   1   0   1   0   0   0\n",
      "8            5  2023-11-13   1   1   0   1   0   0   0\n",
      "9            5  2023-11-14   1   1   0   1   0   1   0\n",
      "10           5  2023-11-15   0   1   0   1   0   0   0\n",
      "11           5  2023-11-16   1   0   0   1   0   0   0\n",
      "12           5  2023-11-17   0   0   0   0   0   0   0\n",
      "13           5  2023-11-18   0   1   0   0   0   0   0\n",
      "14           5  2023-11-19   0   1   0   0   0   0   0\n",
      "15           5  2023-11-20   0   1   0   0   0   0   0\n",
      "16           5  2023-11-21   0   1   0   0   0   0   0\n",
      "17           5  2023-11-22   0   1   0   1   0   0   0\n",
      "18           5  2023-11-23   1   1   0   1   0   0   0\n",
      "19           5  2023-11-24   0   0   0   1   0   0   0\n",
      "20           6  2023-10-06   1   1   0   0   1   1   0\n",
      "21           6  2023-10-07   1   1   1   0   0   1   0\n",
      "22           6  2023-10-08   1   1   1   0   1   1   0\n",
      "23           6  2023-10-09   1   1   1   0   1   1   1\n",
      "24           6  2023-10-10   1   1   1   0   0   1   0\n",
      "25           6  2023-10-11   1   1   1   0   1   1   0\n",
      "26           6  2023-10-12   0   1   1   0   0   1   0\n",
      "27           6  2023-10-13   1   1   1   0   0   1   0\n",
      "28           6  2023-10-14   0   1   1   0   1   1   0\n",
      "29           6  2023-10-15   0   1   1   0   0   1   0\n",
      "30           6  2023-10-16   1   1   1   0   1   1   0\n",
      "31           6  2023-10-17   1   1   1   0   0   1   0\n",
      "32           6  2023-10-18   1   1   1   0   0   1   0\n",
      "33           6  2023-10-19   1   1   1   0   0   1   0\n",
      "34           6  2023-10-20   1   1   0   1   0   0   0\n",
      "35           6  2023-10-21   1   1   1   1   1   1   0\n",
      "36           6  2023-10-22   1   1   1   0   1   1   0\n",
      "37           6  2023-10-23   1   1   1   0   0   1   0\n",
      "38           6  2023-10-24   1   1   0   1   0   0   0\n",
      "39           6  2023-10-25   1   1   1   0   0   1   0\n",
      "40           6  2023-10-26   0   1   1   0   0   1   0\n",
      "41           6  2023-10-27   1   1   1   0   0   1   0\n",
      "42           6  2023-10-28   1   1   1   1   0   1   0\n",
      "43           6  2023-10-29   0   1   1   0   0   1   0\n",
      "44           6  2023-10-30   1   1   0   0   0   0   0\n",
      "45           6  2023-10-31   0   1   0   0   0   1   0\n",
      "46           6  2023-11-01   1   1   1   0   0   1   0\n",
      "47           6  2023-11-02   1   0   1   1   0   0   0\n",
      "48           6  2023-11-03   0   1   1   0   0   0   0\n",
      "49           6  2023-11-04   1   1   1   1   0   1   0\n"
     ]
    }
   ],
   "source": [
    "print(final_df.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(f\"only_valid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('vit_huge_patch14_224', pretrained=False, num_classes=7)\n",
    "model = model.to('cuda')\n",
    "model.load_state_dict(torch.load('./models/base_image.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_conv_layer = model.stages[3].blocks[-1].norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "target_layers = [model.layers[-1].blocks[-1].norm2]\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# 이미지 파일 경로\n",
    "image_path = '..//new_image_dataset/user8_2023-10-23_test.png'\n",
    "\n",
    "# 이미지를 불러오기\n",
    "img = np.array(Image.open(image_path).convert('RGB'))\n",
    "img = img / 255\n",
    "# 모델에 입력하기 위한 전처리 과정 정의\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(384),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[mean, mean, mean], std=[std, std, std]),\n",
    "    \n",
    "])\n",
    "\n",
    "# 이미지를 전처리하고 Tensor로 변환\n",
    "input_tensor = preprocess(image)\n",
    "\n",
    "# 배치 차원 추가 (모델은 일반적으로 배치를 입력으로 받음)\n",
    "rgb_img = input_tensor.unsqueeze(0)\n",
    "# Create an input tensor image for your model..\n",
    "# Note: input_tensor can be a batch tensor with several images!\n",
    "\n",
    "# Construct the CAM object once, and then re-use it on many images:\n",
    "cam = FullGrad(model=model, target_layers=target_layers)\n",
    "\n",
    "# You can also use it within a with statement, to make sure it is freed,\n",
    "# In case you need to re-create it inside an outer loop:\n",
    "# with GradCAM(model=model, target_layers=target_layers) as cam:\n",
    "#   ...\n",
    "\n",
    "# We have to specify the target we want to generate\n",
    "# the Class Activation Maps for.\n",
    "# If targets is None, the highest scoring category\n",
    "# will be used for every image in the batch.\n",
    "# Here we use ClassifierOutputTarget, but you can define your own custom targets\n",
    "# That are, for example, combinations of categories, or specific outputs in a non standard model.\n",
    "\n",
    "targets = [ClassifierOutputTarget(1)]\n",
    "\n",
    "# You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
    "grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "\n",
    "# In this example grayscale_cam has only one image in the batch:\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "visualization = show_cam_on_image(img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "# You can also get the model outputs without having to re-inference\n",
    "model_outputs = cam.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loss, test_acc, test_f1 = run_model(model, test_loader, criterion, optimizer, is_training=False)\n",
    "test_acc, test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.1 (NGC 23.07/Python 3.10) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
